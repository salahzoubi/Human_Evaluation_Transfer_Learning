{
 "cells": [
  {
   "cell_type": "raw",
   "id": "792fc77d-aa34-4589-9b9c-705e542e24ab",
   "metadata": {},
   "source": [
    "### MAUVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9616de6d-0962-4106-9b0a-6e542095a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df[master_df.dataset != \"mauve\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ddfb5c83-e254-4960-9c40-4c5193ec0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Mauve/data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "10d7eede-6c92-45e9-b880-ef44596ac9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0.624691\n",
      "B    0.375309\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 3240\n",
      "total length 6592\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"Mauve/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\") \n",
    "master_df = master_df[master_df.dataset != \"mauve\"]\n",
    "prefix = \"binary classification\"\n",
    "dataset_name= \"mauve\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 1\n",
    "\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Which continuation is more interesting or creative given the context?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt}{row.input_texts}\"]\n",
    "    prelim_df[\"labels\"] += [row.interesting]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5c0e10ab-1300-409a-a1f8-3cbdc01bc6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0.602778\n",
      "B    0.397222\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 3240\n",
      "total length 9832\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Mauve/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\") \n",
    "prefix = \"binary classification\"\n",
    "dataset_name= \"mauve\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 2\n",
    "\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Which continuation is more reasonable, or coherent, given the context?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt}{row.input_texts}\"]\n",
    "    prelim_df[\"labels\"] += [row.reasonable]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "982020dd-b240-47a2-bdba-0c24963c2c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.169     0.000926\n",
      "5.285     0.000926\n",
      "47.753    0.000926\n",
      "6.766     0.000617\n",
      "15.568    0.000617\n",
      "            ...   \n",
      "11.213    0.000309\n",
      "15.293    0.000309\n",
      "20.922    0.000309\n",
      "80.003    0.000309\n",
      "42.669    0.000309\n",
      "Name: labels, Length: 3152, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 3240\n",
      "total length 13072\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"Mauve/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"regression\"\n",
    "dataset_name= \"mauve\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 3\n",
    "\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On average, how much time did this task take?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt}{row.input_texts}\"]\n",
    "    prelim_df[\"labels\"] += [row.time_taken]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f6a1a-0583-417c-9ae2-0230ec1627ad",
   "metadata": {},
   "source": [
    "### wikisum amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a5d110b-7789-42a2-8bea-c0a2c6aaa4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    0.285714\n",
      "4    0.261905\n",
      "3    0.261905\n",
      "1    0.142857\n",
      "5    0.047619\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 42\n",
      "total length 9762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"WikiSum/human_eval.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"wikisum\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 4\n",
    "\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale of 1 to 5, how difficult is annotating this task?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Document: {row.doc}. Model Summary: {row.generated}. Human Summary: {row.summary}\"]\n",
    "    prelim_df[\"labels\"] += [row.hard]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc2b9f41-73e3-4943-a525-f4380c6f6185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    0.309524\n",
      "4    0.285714\n",
      "3    0.190476\n",
      "5    0.119048\n",
      "1    0.095238\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 42\n",
      "total length 9804\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"WikiSum/human_eval.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"wikisum\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 5\n",
    "\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale of 1 to 5, how tiring is annotating this task?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Document: {row.doc}. Model Summary: {row.generated}. Human Summary: {row.summary}\"]\n",
    "    prelim_df[\"labels\"] += [row.tiring]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1412b475-aa6a-4a7b-a6aa-f33d5a634951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.309524\n",
      "4    0.285714\n",
      "2    0.166667\n",
      "3    0.119048\n",
      "1    0.119048\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 42\n",
      "total length 9846\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"WikiSum/human_eval.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"wikisum\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 6\n",
    "\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale of 1 to 5, how coherent is the model's output?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Document: {row.doc}. Model Summary: {row.generated}. Human Summary: {row.summary}\"]\n",
    "    prelim_df[\"labels\"] += [row.coh]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5f88e98-be0d-4d46-8052-5190cc290ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0     0.190476\n",
      "11.0    0.119048\n",
      "10.0    0.119048\n",
      "6.0     0.095238\n",
      "9.0     0.095238\n",
      "7.0     0.071429\n",
      "15.0    0.047619\n",
      "8.0     0.047619\n",
      "7.5     0.047619\n",
      "10.5    0.047619\n",
      "12.0    0.023810\n",
      "4.0     0.023810\n",
      "3.0     0.023810\n",
      "14.0    0.023810\n",
      "13.0    0.023810\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 42\n",
      "total length 9930\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"WikiSum/human_eval.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"wikisum\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 8\n",
    "\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On average, how much time did this task take?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Document: {row.doc}. Model Summary: {row.generated}. Human Summary: {row.summary}\"]\n",
    "    prelim_df[\"labels\"] += [row.time]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76ad97f1-d36e-49d5-a594-c8e24c34e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.input_text = master_df.input_text.apply(lambda x: f\"{x}</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "314c48a3-5ff8-4489-8ed9-8580f8d2f5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6    0.617068\n",
      "2    0.166302\n",
      "1    0.075492\n",
      "5    0.059081\n",
      "3    0.047046\n",
      "4    0.035011\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 914\n",
      "total length 10844\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"RankME/f1204299.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"rankme\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 9\n",
    "\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"How informative is the following automatically generated utterance?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Model Output: {row.mr}. Human Reference: {row.ref}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.informativeness]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab7bb43f-042e-413e-b53c-dbf36480f989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6    0.835886\n",
      "5    0.137856\n",
      "4    0.021882\n",
      "2    0.003282\n",
      "3    0.001094\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 914\n",
      "total length 11758\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"RankME/f1204299.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"rankme\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 10\n",
    "\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"How would you rate the quality of the following automatically generated utterance?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Model Output: {row.mr}. Human Reference: {row.ref}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.quality]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92e54341-0783-4edd-ab92-d9959edf442d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6    0.867615\n",
      "5    0.103939\n",
      "4    0.025164\n",
      "1    0.002188\n",
      "3    0.001094\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 914\n",
      "total length 12672\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"RankME/f1204299.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"rankme\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 11\n",
    "\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"How natural, or human-like, is the following automatically generated utterance?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Model Output: {row.mr}. Human Reference: {row.ref}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.naturalness]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c78c1-6e77-4828-803d-66ceb1b1b966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b1d25e8-3da2-473a-8fdf-5fda94ed0be1",
   "metadata": {},
   "source": [
    "### tgoyal_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f440caf5-4dd6-4d71-845b-3945fac583d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B    0.595\n",
      "C    0.235\n",
      "A    0.170\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 200\n",
      "total length 12872\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"rankme\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 12\n",
    "SWITCH = {\"t0\": \"A\", \"gpt3\": \"B\", \"brio\": \"C\"}\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Which model output is the most clear, concise and overall the best?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Article: {row.article}. Model A: {row.t0}. Model B: {row.gpt3}. Model C: {row.brio}</s>\"]\n",
    "    best_model = ast.literal_eval(row.labels)\n",
    "    prelim_df[\"labels\"] += [SWITCH[best_model['best_model']]]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1107335-7686-4bf9-a3fc-d9ff1a791eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0.450\n",
      "C    0.345\n",
      "B    0.205\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 200\n",
      "total length 13072\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"rankme\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 13\n",
    "SWITCH = {\"t0\": \"A\", \"gpt3\": \"B\", \"brio\": \"C\"}\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Which model output is the least clear, concise and overall the best?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Article: {row.article}. Model A: {row.t0}. Model B: {row.gpt3}. Model C: {row.brio}</s>\"]\n",
    "    best_model = ast.literal_eval(row.labels)\n",
    "    prelim_df[\"labels\"] += [SWITCH[best_model['worst_model']]]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b869eaf-5051-4582-8e57-d6e44beda4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9cd69d6-295c-47a6-93ee-1d03c3cda3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv(\"master_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "792d0c82-b8c7-4563-ba55-c9ccd9d65036",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in master_df.iterrows():\n",
    "    if row.task_id == 13 or row.task_id == 12:\n",
    "        row.dataset = \"tgoyal_news\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5f285b0-5590-4d0b-941f-e446a81a9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_df = master_df[(master_df.task_id == 12) | (master_df.task_id==13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bc205bea-bdb5-4a48-be0a-f0a29aa46906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ials-gpu006/5455943/ipykernel_1243280/671335498.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  other_df.dataset = \"tgoyal_news\"\n"
     ]
    }
   ],
   "source": [
    "other_df.dataset = \"tgoyal_news\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c46b85fb-0078-4482-8358-a1922b2aad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df = master_df[~master_df.task_id.isin([12,13])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "467c7568-c880-4e84-a929-5268ded91add",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([first_df, other_df]).sample(frac=1).to_csv(\"master_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1291145e-ee1e-4ec1-b1fd-f143dc051d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a2514-a775-472a-9bce-8ab77547f560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb0489c5-d08b-45fa-8e33-3c3615e06ee3",
   "metadata": {},
   "source": [
    "### WMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a3e7a62b-56d7-4f5c-ade5-7b9fed7df442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"WMT/generalMT2022/ende/mqm_generalMT2022_ende.tsv\", on_bad_lines='skip', sep=\"\\t\")\n",
    "df2 = pd.read_csv(\"WMT/newstest2021/ende/mqm_newstest2021_ende.tsv\", on_bad_lines='skip', sep=\"\\t\")\n",
    "df3 = pd.read_csv(\"WMT/newstest2020/ende/mqm_newstest2020_ende.tsv\", on_bad_lines=\"skip\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d1eae67f-df0a-4f8f-ad2f-c7922ac5ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b89733f0-7a46-4fef-930f-0b7c54a37c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = df[~df.severity.isin([np.nan, \"word order\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fb70e213-94f9-43c9-b7e8-8240057cd5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ials-gpu006/5455943/ipykernel_1243280/3068952031.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.severity = df.severity.apply(lambda x: x.lower())\n"
     ]
    }
   ],
   "source": [
    "df.severity = df.severity.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7b3a0887-2e35-47a7-8509-21158382796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minor       0.614397\n",
      "no-error    0.262457\n",
      "major       0.108309\n",
      "neutral     0.014837\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 117608\n",
      "total length 130680\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"wmt_en_de\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 14\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the following English to German translation, what is the severity of the type of errors are present?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} English Source: {row.source}. German Translation: {row.target}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.severity]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8c308e99-a544-49b2-88ed-ebd3d361dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv(\"master_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ca829b29-cdba-4463-8718-e49c9dc9421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df[~(master_df.task_id == 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5ad6e048-58e0-43ee-a54c-5c090b090c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"WMT/generalMT2022/enru/mqm_generalMT2022_enru.tsv\", on_bad_lines='skip', sep=\"\\t\")\n",
    "# df2 = pd.read_csv(\"WMT/newstest2021/\", on_bad_lines='skip', sep=\"\\t\")\n",
    "# df3 = pd.read_csv(\"WMT/newstest2020/\", on_bad_lines=\"skip\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f7cdab56-5a9b-447a-8f7a-8e0b08032d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "SWITCH = {\"critical\": \"major\", \"neutral\": \"no-error\", \"minor\": \"minor\", \"major\":\"major\", \"no-error\": \"no-error\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b216c39d-b6cb-42d5-ae71-14111b70f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.category = df.category.apply(lambda x: SWITCH[x.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2def7141-9144-43ed-b4fb-e27ba0ca5aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no-error', 'minor', 'major'], dtype=object)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "01c1f2f0-78dc-424b-902e-f6e239184998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minor       0.450193\n",
      "no-error    0.295312\n",
      "major       0.254495\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 33981\n",
      "total length 164661\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "# master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"wmt_en_ru\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 15\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the following English to Russian translation, what is the severity of the type of errors are present?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} English Source: {row.source}. Russian Translation: {row.target}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.category]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96197b-12b2-44b7-badf-8a4c9c3c9653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "42dcde5c-0f4f-410a-9f78-b99d553d829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"WMT/generalMT2022/zhen/mqm_generalMT2022_zhen.tsv\", on_bad_lines='skip', sep=\"\\t\")\n",
    "df2 = pd.read_csv(\"WMT/newstest2021/zhen/mqm_newstest2021_zhen.tsv\", on_bad_lines='skip', sep=\"\\t\")\n",
    "df3 = pd.read_csv(\"WMT/newstest2020/zhen/mqm_newstest2020_zhen.tsv\", on_bad_lines='skip', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "63e70983-f831-4441-937d-dd93ff0ee2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "457b6e0c-59c0-4123-bbad-6bece8f7033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.severity != \"HOTW-test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a0aa76fc-c241-44a0-a837-3caa1bf27b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SWITCH = {\"critical\": \"major\", \"neutral\": \"no-error\", \"minor\": \"minor\", \"major\":\"major\", \"no-error\": \"no-error\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cfabd9cf-d724-44bc-a1a1-5cc8f5377e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.severity = df.severity.apply(lambda x: SWITCH[x.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cc3ac5ac-3ba9-4862-97a1-c7645c0a4642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no-error', 'minor', 'major'], dtype=object)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.severity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "28b4df98-1aff-4bc5-8c16-c96280fead30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minor       0.419081\n",
      "major       0.398905\n",
      "no-error    0.182014\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 186909\n",
      "total length 351570\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"wmt_zh_en\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 16\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the following English to Chinese translation, what is the severity of the type of errors are present?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} English Source: {row.source}. Chinese Translation: {row.target}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.severity]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05550bc9-1166-42f8-95a7-a975d156df27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "907dfc64-9446-4262-a602-6c4331558d59",
   "metadata": {},
   "source": [
    "### PeerRead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd0ab39e-a324-43dd-9b98-0c5e0b49fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"PeerRead/acl_processed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b6972b-dfa8-48b9-abea-c3b433c04a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.impact != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60112943-0e1e-4575-ad1e-00937389df7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>impact</th>\n",
       "      <th>substance</th>\n",
       "      <th>appropriateness</th>\n",
       "      <th>presentation_format</th>\n",
       "      <th>meaningful_comparison</th>\n",
       "      <th>correctness</th>\n",
       "      <th>originality</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>clarity</th>\n",
       "      <th>confidence</th>\n",
       "      <th>comments</th>\n",
       "      <th>conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104.0</td>\n",
       "      <td>Bridge Text and Knowledge by Learning Multi-Pr...</td>\n",
       "      <td>Integrating text and knowledge into a unified ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Oral Presentation</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>- Strengths:\\nGood ideas, simple neural learni...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.0</td>\n",
       "      <td>Morphological Inflection Generation with Hard ...</td>\n",
       "      <td>We present a neural model for morphological in...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Oral Presentation</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>- Strengths: A new encoder-decoder model is pr...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.0</td>\n",
       "      <td>Weakly Supervised Cross-Lingual Named Entity R...</td>\n",
       "      <td>The state-of-the-art named entity recognition ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Poster</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper describes a model for cross-lingual...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108.0</td>\n",
       "      <td>A Multigraph-based Model for Overlapping Entit...</td>\n",
       "      <td>In this paper, we propose a new model for pred...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Poster</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The paper suggests an approach based on multig...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.0</td>\n",
       "      <td>Improved Neural Relation Detection for Knowled...</td>\n",
       "      <td>Relation detection is a core component of many...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Oral Presentation</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>- Strengths: The paper addresses a relevant to...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  104.0  Bridge Text and Knowledge by Learning Multi-Pr...   \n",
       "1  105.0  Morphological Inflection Generation with Hard ...   \n",
       "2  107.0  Weakly Supervised Cross-Lingual Named Entity R...   \n",
       "3  108.0  A Multigraph-based Model for Overlapping Entit...   \n",
       "4  117.0  Improved Neural Relation Detection for Knowled...   \n",
       "\n",
       "                                            abstract  impact  substance  \\\n",
       "0  Integrating text and knowledge into a unified ...       3          4   \n",
       "1  We present a neural model for morphological in...       3          4   \n",
       "2  The state-of-the-art named entity recognition ...       3          4   \n",
       "3  In this paper, we propose a new model for pred...       3          3   \n",
       "4  Relation detection is a core component of many...       3          5   \n",
       "\n",
       "   appropriateness presentation_format  meaningful_comparison  correctness  \\\n",
       "0                4   Oral Presentation                      2            4   \n",
       "1                5   Oral Presentation                      2            4   \n",
       "2                5              Poster                      2            4   \n",
       "3                5              Poster                      2            4   \n",
       "4                5   Oral Presentation                      2            4   \n",
       "\n",
       "   originality  recommendation  clarity  confidence  \\\n",
       "0            3               3        3           3   \n",
       "1            3               3        5           3   \n",
       "2            3               3        4           3   \n",
       "3            3               2        3           3   \n",
       "4            3               4        4           4   \n",
       "\n",
       "                                            comments conference  \n",
       "0  - Strengths:\\nGood ideas, simple neural learni...   ACL_2017  \n",
       "1  - Strengths: A new encoder-decoder model is pr...   ACL_2017  \n",
       "2  This paper describes a model for cross-lingual...   ACL_2017  \n",
       "3  The paper suggests an approach based on multig...   ACL_2017  \n",
       "4  - Strengths: The paper addresses a relevant to...   ACL_2017  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71e92f46-f211-4209-ac84-19c01944f576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    0.754839\n",
      "4    0.141935\n",
      "2    0.070968\n",
      "5    0.025806\n",
      "1    0.006452\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 155\n",
      "total length 351725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"peer_read\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 17\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the following conference, title, abstract and reviewer comments, what would you rate the impact of this paper on a scale from 1-5?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Conference: {row.conference}. Title: {row.title}. Abstract: {row.abstract}. Comments: {row.comments}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.impact]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bbb3a01-c0c0-4500-a2de-a6bc2478e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    0.574194\n",
      "3    0.225806\n",
      "5    0.116129\n",
      "2    0.083871\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 155\n",
      "total length 351880\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"peer_read\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 18\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the following conference, title, abstract and reviewer comments, what would you rate the clarity of this paper on a scale from 1-5?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Conference: {row.conference}. Title: {row.title}. Abstract: {row.abstract}. Comments: {row.comments}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.clarity]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1634ab6f-d1fc-4716-ac18-abea8f5f9f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.825806\n",
      "4    0.148387\n",
      "3    0.019355\n",
      "2    0.006452\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 155\n",
      "total length 352035\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"peer_read\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 19\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the following conference, title, abstract and reviewer comments, what would you rate the appropriateness of this paper on a scale from 1-5?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Conference: {row.conference}. Title: {row.title}. Abstract: {row.abstract}. Comments: {row.comments}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.appropriateness]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d614b3b8-773d-4341-ad02-5bb767e64cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>impact</th>\n",
       "      <th>substance</th>\n",
       "      <th>appropriateness</th>\n",
       "      <th>presentation_format</th>\n",
       "      <th>meaningful_comparison</th>\n",
       "      <th>correctness</th>\n",
       "      <th>originality</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>clarity</th>\n",
       "      <th>confidence</th>\n",
       "      <th>comments</th>\n",
       "      <th>conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104.0</td>\n",
       "      <td>Bridge Text and Knowledge by Learning Multi-Pr...</td>\n",
       "      <td>Integrating text and knowledge into a unified ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Oral Presentation</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>- Strengths:\\nGood ideas, simple neural learni...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.0</td>\n",
       "      <td>Morphological Inflection Generation with Hard ...</td>\n",
       "      <td>We present a neural model for morphological in...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Oral Presentation</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>- Strengths: A new encoder-decoder model is pr...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107.0</td>\n",
       "      <td>Weakly Supervised Cross-Lingual Named Entity R...</td>\n",
       "      <td>The state-of-the-art named entity recognition ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Poster</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>This paper describes a model for cross-lingual...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108.0</td>\n",
       "      <td>A Multigraph-based Model for Overlapping Entit...</td>\n",
       "      <td>In this paper, we propose a new model for pred...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Poster</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>The paper suggests an approach based on multig...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.0</td>\n",
       "      <td>Improved Neural Relation Detection for Knowled...</td>\n",
       "      <td>Relation detection is a core component of many...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Oral Presentation</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>- Strengths: The paper addresses a relevant to...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11928</th>\n",
       "      <td>91.0</td>\n",
       "      <td>Compression of Neural Machine Translation Mode...</td>\n",
       "      <td>Neural Machine Translation (NMT), like many ot...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Poster</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>This paper applies the idea of translation mod...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11929</th>\n",
       "      <td>98.0</td>\n",
       "      <td>Delexicalized and Minimally Supervised Parsing...</td>\n",
       "      <td>In this paper, we compare delexicalized transf...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Poster</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>This paper evaluates a minimally supervised de...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11930</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Identifying Temporal Orientation of Word Senses</td>\n",
       "      <td>The ability to capture time information is ess...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Oral Presentation</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>This paper presents an approach to tag word se...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11931</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Event Linking with Sentential Features from Co...</td>\n",
       "      <td>Coreference resolution for event mentions enab...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Oral Presentation</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>This paper presents a model for the task of ev...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11932</th>\n",
       "      <td>151.0</td>\n",
       "      <td>Parsing for Universal Dependencies without tra...</td>\n",
       "      <td>We present UDP, an unsupervised parsing algori...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Poster</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>This paper presents a way to parse trees (name...</td>\n",
       "      <td>ACL_2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0      104.0  Bridge Text and Knowledge by Learning Multi-Pr...   \n",
       "1      105.0  Morphological Inflection Generation with Hard ...   \n",
       "2      107.0  Weakly Supervised Cross-Lingual Named Entity R...   \n",
       "3      108.0  A Multigraph-based Model for Overlapping Entit...   \n",
       "4      117.0  Improved Neural Relation Detection for Knowled...   \n",
       "...      ...                                                ...   \n",
       "11928   91.0  Compression of Neural Machine Translation Mode...   \n",
       "11929   98.0  Delexicalized and Minimally Supervised Parsing...   \n",
       "11930   25.0    Identifying Temporal Orientation of Word Senses   \n",
       "11931   13.0  Event Linking with Sentential Features from Co...   \n",
       "11932  151.0  Parsing for Universal Dependencies without tra...   \n",
       "\n",
       "                                                abstract  impact  substance  \\\n",
       "0      Integrating text and knowledge into a unified ...       3          4   \n",
       "1      We present a neural model for morphological in...       3          4   \n",
       "2      The state-of-the-art named entity recognition ...       3          4   \n",
       "3      In this paper, we propose a new model for pred...       3          3   \n",
       "4      Relation detection is a core component of many...       3          5   \n",
       "...                                                  ...     ...        ...   \n",
       "11928  Neural Machine Translation (NMT), like many ot...       3          3   \n",
       "11929  In this paper, we compare delexicalized transf...       2          3   \n",
       "11930  The ability to capture time information is ess...       4          4   \n",
       "11931  Coreference resolution for event mentions enab...       2          4   \n",
       "11932  We present UDP, an unsupervised parsing algori...       3          3   \n",
       "\n",
       "       appropriateness presentation_format  meaningful_comparison  \\\n",
       "0                    4   Oral Presentation                      2   \n",
       "1                    5   Oral Presentation                      2   \n",
       "2                    5              Poster                      2   \n",
       "3                    5              Poster                      2   \n",
       "4                    5   Oral Presentation                      2   \n",
       "...                ...                 ...                    ...   \n",
       "11928                5              Poster                      4   \n",
       "11929                5              Poster                      3   \n",
       "11930                5   Oral Presentation                      5   \n",
       "11931                5   Oral Presentation                      4   \n",
       "11932                5              Poster                      4   \n",
       "\n",
       "       correctness  originality  recommendation  clarity  confidence  \\\n",
       "0                4            3               3        3           3   \n",
       "1                4            3               3        5           3   \n",
       "2                4            3               3        4           3   \n",
       "3                4            3               2        3           3   \n",
       "4                4            3               4        4           4   \n",
       "...            ...          ...             ...      ...         ...   \n",
       "11928            4            2               3        4           4   \n",
       "11929            3            2               2        4           4   \n",
       "11930            4            3               4        4           2   \n",
       "11931            3            3               3        4           4   \n",
       "11932            4            2               3        4           4   \n",
       "\n",
       "                                                comments conference  \n",
       "0      - Strengths:\\nGood ideas, simple neural learni...   ACL_2017  \n",
       "1      - Strengths: A new encoder-decoder model is pr...   ACL_2017  \n",
       "2      This paper describes a model for cross-lingual...   ACL_2017  \n",
       "3      The paper suggests an approach based on multig...   ACL_2017  \n",
       "4      - Strengths: The paper addresses a relevant to...   ACL_2017  \n",
       "...                                                  ...        ...  \n",
       "11928  This paper applies the idea of translation mod...   ACL_2017  \n",
       "11929  This paper evaluates a minimally supervised de...   ACL_2017  \n",
       "11930  This paper presents an approach to tag word se...   ACL_2017  \n",
       "11931  This paper presents a model for the task of ev...   ACL_2017  \n",
       "11932  This paper presents a way to parse trees (name...   ACL_2017  \n",
       "\n",
       "[155 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa7d7fb4-71e1-443c-b8ce-4483b21ad205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    0.464516\n",
      "3    0.380645\n",
      "2    0.090323\n",
      "5    0.045161\n",
      "1    0.019355\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 155\n",
      "total length 352190\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"peer_read\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 20\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the following conference, title, abstract and reviewer comments, what would you rate the substance of this paper on a scale from 1-5?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Conference: {row.conference}. Title: {row.title}. Abstract: {row.abstract}. Comments: {row.comments}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.substance]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44deae30-db78-4697-a01b-fb5b060aac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    0.380645\n",
      "5    0.380645\n",
      "4    0.225806\n",
      "2    0.012903\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 155\n",
      "total length 352345\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"peer_read\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 21\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the following conference, title, abstract and reviewer comments, what would you rate the correctness of this paper on a scale from 1-5?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Conference: {row.conference}. Title: {row.title}. Abstract: {row.abstract}. Comments: {row.comments}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.correctness]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a59a527d-bf47-4dc7-95d8-6206a20efc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    0.425806\n",
      "5    0.277419\n",
      "4    0.251613\n",
      "2    0.045161\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 155\n",
      "total length 352500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"peer_read\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 22\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the following conference, title, abstract and reviewer comments, what would you rate the originality of this paper on a scale from 1-5?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Conference: {row.conference}. Title: {row.title}. Abstract: {row.abstract}. Comments: {row.comments}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.originality]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d6334f5-4d6c-4927-9cf0-cd2494fb770f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4]    0.232258\n",
      "[3, 4]    0.167742\n",
      "[3, 3]    0.129032\n",
      "[2, 4]    0.129032\n",
      "[4, 3]    0.083871\n",
      "[2, 3]    0.083871\n",
      "[4, 5]    0.045161\n",
      "[4, 2]    0.038710\n",
      "[5, 4]    0.019355\n",
      "[3, 2]    0.012903\n",
      "[3, 5]    0.012903\n",
      "[1, 4]    0.012903\n",
      "[2, 5]    0.006452\n",
      "[5, 5]    0.006452\n",
      "[2, 2]    0.006452\n",
      "[1, 3]    0.006452\n",
      "[1, 5]    0.006452\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 155\n",
      "total length 352655\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"TGoyal_news_summarization/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multilabel multiclass classification\"\n",
    "dataset_name= \"peer_read\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 23\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the following conference, title, abstract and reviewer comments, what recommendation for accepting/rejecting this paper would you give on a scale from 1-5? On a scale from 1-5 how confident are you in your recommendation?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Conference: {row.conference}. Title: {row.title}. Abstract: {row.abstract}. Comments: {row.comments}</s>\"]\n",
    "    prelim_df[\"labels\"] += [f\"[{row.recommendation}, {row.confidence}]\"]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f4f8ac-614f-492d-b02c-360450f5d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv(\"master_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ce363c-ef60-4f72-9a08-0e177b282616",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df[~(master_df.task_id == 24)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d42c11-8c19-403b-89fc-40cbaed97b22",
   "metadata": {},
   "source": [
    "### LENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb40f201-e385-4206-bceb-68c236117c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"LENS/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "782ee9d4-b145-4c46-8607-c0284f0c7b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>Input.id</th>\n",
       "      <th>Input.original</th>\n",
       "      <th>Input.simplified</th>\n",
       "      <th>Input.system</th>\n",
       "      <th>Answer.adequacy</th>\n",
       "      <th>Answer.fluency</th>\n",
       "      <th>Answer.simplicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>On the fifth day of flight, November 20, 2022,...</td>\n",
       "      <td>On November 20, 2022, the Orion spacecraft sta...</td>\n",
       "      <td>GPT-3-few-shot</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>On the fifth day of flight, November 20, 2022,...</td>\n",
       "      <td>On November 20, 2022, the Orion spacecraft sta...</td>\n",
       "      <td>GPT-3-few-shot</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>On the fifth day of flight, November 20, 2022,...</td>\n",
       "      <td>On November 20, 2022, the Orion spacecraft sta...</td>\n",
       "      <td>GPT-3-few-shot</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>The complainant claimed that he had not renoun...</td>\n",
       "      <td>The complaint said he did not renounce his Nep...</td>\n",
       "      <td>Human 2 Writing</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>The complainant claimed that he had not renoun...</td>\n",
       "      <td>The complaint said he did not renounce his Nep...</td>\n",
       "      <td>Human 2 Writing</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WorkerId  Input.id                                     Input.original  \\\n",
       "0         0        40  On the fifth day of flight, November 20, 2022,...   \n",
       "1         1        40  On the fifth day of flight, November 20, 2022,...   \n",
       "2         2        40  On the fifth day of flight, November 20, 2022,...   \n",
       "3         3        53  The complainant claimed that he had not renoun...   \n",
       "4         1        53  The complainant claimed that he had not renoun...   \n",
       "\n",
       "                                    Input.simplified     Input.system  \\\n",
       "0  On November 20, 2022, the Orion spacecraft sta...   GPT-3-few-shot   \n",
       "1  On November 20, 2022, the Orion spacecraft sta...   GPT-3-few-shot   \n",
       "2  On November 20, 2022, the Orion spacecraft sta...   GPT-3-few-shot   \n",
       "3  The complaint said he did not renounce his Nep...  Human 2 Writing   \n",
       "4  The complaint said he did not renounce his Nep...  Human 2 Writing   \n",
       "\n",
       "   Answer.adequacy  Answer.fluency  Answer.simplicity  \n",
       "0                5               5                  2  \n",
       "1                4               3                  2  \n",
       "2                5               5                  2  \n",
       "3                2               4                  1  \n",
       "4                2               1                  2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b06b0a-2c0b-48a6-b0ec-79428aa30806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ebf166-b349-4116-9566-924af0037fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.722222\n",
      "4    0.212963\n",
      "3    0.040741\n",
      "2    0.022222\n",
      "1    0.001852\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 1080\n",
      "total length 353735\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"LENS/data.csv\")\n",
    "# master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"lens\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 24\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-5, how fluent is the model's generation given an original phrase?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Original: {row['Input.original']}. Model Generation: {row['Input.simplified']}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row[\"Answer.fluency\"]]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71def441-39ec-4561-92ad-e8c06519c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "master_df = master_df[~(master_df.task_id == 25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9401e1d-3d03-4f16-9ff0-857541b63a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    0.398148\n",
      "5    0.329630\n",
      "3    0.249074\n",
      "2    0.020370\n",
      "1    0.002778\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 1080\n",
      "total length 354815\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"LENS/data.csv\")\n",
    "# master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"lens\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 25\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-5, how simple, or concice, is the model's generation given an original phrase?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Original: {row['Input.original']}. Model Generation: {row['Input.simplified']}</s>\"]\n",
    "    prelim_df[\"labels\"] += [int(row[\"Answer.simplicity\"]) + 3]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7016a0a5-18a4-4eea-ab95-da3904abef15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.655556\n",
      "4    0.200000\n",
      "3    0.079630\n",
      "2    0.053704\n",
      "1    0.011111\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 1080\n",
      "total length 355895\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"LENS/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"lens\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 26\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-5, how adequate is the model's generation given an original phrase?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Original: {row['Input.original']}. Model Generation: {row['Input.simplified']}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row[\"Answer.adequacy\"]]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b45d7e-66d5-4066-bc8c-ff199f0481a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98a8e1d0-d5ba-47ba-97f8-0173c78cd748",
   "metadata": {},
   "source": [
    "### DIALOG EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be10e25-49dc-4194-b303-eaacba5297ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Dialogue-Eval/data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5b45843-e69a-46cc-9686-69288c40977d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>robotic</th>\n",
       "      <th>interesting</th>\n",
       "      <th>fun</th>\n",
       "      <th>consistent</th>\n",
       "      <th>fluent</th>\n",
       "      <th>repetitive</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'Hi'}, {...</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>90</td>\n",
       "      <td>34</td>\n",
       "      <td>4942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'Why are...</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'women'}...</td>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>95</td>\n",
       "      <td>98</td>\n",
       "      <td>95</td>\n",
       "      <td>100</td>\n",
       "      <td>1821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'Are you...</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>79</td>\n",
       "      <td>64</td>\n",
       "      <td>1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'I like ...</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "      <td>49</td>\n",
       "      <td>61</td>\n",
       "      <td>3120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  robotic  interesting  \\\n",
       "0  [{'participant': 'user', 'utterance': 'Hi'}, {...        4           93   \n",
       "1  [{'participant': 'user', 'utterance': 'Why are...        3           50   \n",
       "2  [{'participant': 'user', 'utterance': 'women'}...        5           98   \n",
       "3  [{'participant': 'user', 'utterance': 'Are you...        1           57   \n",
       "4  [{'participant': 'user', 'utterance': 'I like ...        4           71   \n",
       "\n",
       "   fun  consistent  fluent  repetitive  time_taken  \n",
       "0   85          79      90          34        4942  \n",
       "1   50           3      50         100         692  \n",
       "2   95          98      95         100        1821  \n",
       "3   57           6      79          64        1765  \n",
       "4   70          72      49          61        3120  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a065d61f-5218-4ba4-b4bb-fa43dd370918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_bucket(x):\n",
    "    if 0 <= x <= 20:\n",
    "        return 1\n",
    "    elif 20 < x <= 40:\n",
    "        return 2\n",
    "    elif 40 < x <= 60:\n",
    "        return 3\n",
    "    elif 60 < x <= 80:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a900df-3659-4722-a48a-9698c85a8153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.robotic = df.robotic.apply(lambda x: return_bucket(x))\n",
    "df.interesting = df.interesting.apply(lambda x: return_bucket(x))\n",
    "df.fun = df.fun.apply(lambda x: return_bucket(x))\n",
    "df.consistent = df.consistent.apply(lambda x: return_bucket(x))\n",
    "df.fluent = df.fluent.apply(lambda x: return_bucket(x))\n",
    "df.repetitive = df.repetitive.apply(lambda x: return_bucket(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbc7211e-e902-40e5-bf3a-9a91a565c46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>robotic</th>\n",
       "      <th>interesting</th>\n",
       "      <th>fun</th>\n",
       "      <th>consistent</th>\n",
       "      <th>fluent</th>\n",
       "      <th>repetitive</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'Hi'}, {...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'Why are...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'women'}...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'Are you...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'I like ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>[{'participant': 'user', 'utterance': \"I'm in ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'maratho...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5313</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'do you ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5314</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'hi'}, {...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>[{'participant': 'user', 'utterance': 'hello'}...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5316 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dialogue  robotic  interesting  \\\n",
       "0     [{'participant': 'user', 'utterance': 'Hi'}, {...        4            5   \n",
       "1     [{'participant': 'user', 'utterance': 'Why are...        3            3   \n",
       "2     [{'participant': 'user', 'utterance': 'women'}...        5            5   \n",
       "3     [{'participant': 'user', 'utterance': 'Are you...        1            3   \n",
       "4     [{'participant': 'user', 'utterance': 'I like ...        4            4   \n",
       "...                                                 ...      ...          ...   \n",
       "5311  [{'participant': 'user', 'utterance': \"I'm in ...        5            1   \n",
       "5312  [{'participant': 'user', 'utterance': 'maratho...        5            1   \n",
       "5313  [{'participant': 'user', 'utterance': 'do you ...        5            4   \n",
       "5314  [{'participant': 'user', 'utterance': 'hi'}, {...        4            5   \n",
       "5315  [{'participant': 'user', 'utterance': 'hello'}...        4            3   \n",
       "\n",
       "      fun  consistent  fluent  repetitive  time_taken  \n",
       "0       5           4       5           2        4942  \n",
       "1       3           1       3           5         692  \n",
       "2       5           5       5           5        1821  \n",
       "3       3           1       4           4        1765  \n",
       "4       4           4       3           4        3120  \n",
       "...   ...         ...     ...         ...         ...  \n",
       "5311    1           1       1           1        2611  \n",
       "5312    1           1       1           1        1289  \n",
       "5313    4           4       5           2        1496  \n",
       "5314    5           5       5           5        2594  \n",
       "5315    4           3       4           3        3526  \n",
       "\n",
       "[5316 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11fcddb4-7810-43ea-81c0-f05bd39156ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    0.243980\n",
      "1    0.219338\n",
      "3    0.202032\n",
      "5    0.197141\n",
      "2    0.137509\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 5316\n",
      "total length 361211\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"LENS/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"dialog_eval\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 27\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-5, how fluent is the following dialogue between a user and the chatbot?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Dialogue: {df.dialogue}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.fluent]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea88f7aa-5aa0-4163-a1a1-b620e273676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.306433\n",
      "4    0.226674\n",
      "3    0.174567\n",
      "5    0.148044\n",
      "2    0.144281\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 5316\n",
      "total length 366527\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"LENS/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"dialog_eval\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 28\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-5, how interesting is the following dialogue between a user and the chatbot?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Dialogue: {df.dialogue}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.interesting]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "118c934f-9631-453a-b549-4c073be38a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.303236\n",
      "4    0.209744\n",
      "3    0.170805\n",
      "5    0.166290\n",
      "2    0.149925\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 5316\n",
      "total length 371843\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"LENS/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"dialog_eval\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 29\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-5, how consistent, or coherent, is the following dialogue between a user and the chatbot?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Dialogue: {df.dialogue}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.consistent]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5713f179-9cab-4ce8-9bd7-b9326493a98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.378480\n",
      "4    0.235704\n",
      "3    0.151806\n",
      "1    0.132430\n",
      "2    0.101580\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 5316\n",
      "total length 377159\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"LENS/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"dialog_eval\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 30\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-5, how repetitive is the following dialogue between a user and the chatbot?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Dialogue: {df.dialogue}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.repetitive]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a094d-8f74-4394-8dd2-5a205a047250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"LENS/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"dialog_eval\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 30\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-5, how repetitive is the following dialogue between a user and the chatbot?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Dialogue: {df.dialogue}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.repetitive]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99374b77-6fd5-452f-b79e-f13650fcbaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.537998\n",
      "4    0.216140\n",
      "3    0.124718\n",
      "2    0.067532\n",
      "1    0.053612\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 5316\n",
      "total length 387791\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"LENS/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"dialog_eval\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 32\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-5, how robotic is the following dialogue between a user and the chatbot?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Dialogue: {df.dialogue}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.robotic]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64ed5ac1-6ea9-48b4-b9ac-0f34c039c769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3245    0.004515\n",
      "3661    0.003386\n",
      "1683    0.003386\n",
      "2246    0.003386\n",
      "1812    0.003386\n",
      "          ...   \n",
      "2020    0.001129\n",
      "2948    0.001129\n",
      "4191    0.001129\n",
      "1546    0.001129\n",
      "2793    0.001129\n",
      "Name: labels, Length: 787, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 5316\n",
      "total length 393107\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "# df = pd.read_csv(\"LENS/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"regression\"\n",
    "dataset_name= \"dialog_eval\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 33\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On average, how much time did this task take?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Dialogue: {df.dialogue}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.time_taken]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa634db0-7aad-4922-ac18-d2e46704bd31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89e65561-617c-4d02-89b8-0be43aac192c",
   "metadata": {},
   "source": [
    "### AggreFact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0eb58fc-0fc6-4826-9f53-08093faa6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"AggreFact/data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "140685db-8709-42cb-a3c2-8a2fccd53868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>model</th>\n",
       "      <th>consistent</th>\n",
       "      <th>DAE_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Media playback is not supported on this device...</td>\n",
       "      <td>World number one Dustin Johnson has pulled out...</td>\n",
       "      <td>BART</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There would have been no mercy in the dressing...</td>\n",
       "      <td>ben stokes broke his wrist punching a locker a...</td>\n",
       "      <td>T5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.874552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The couple, who have been dating since 2011, w...</td>\n",
       "      <td>Oscar-winning actress Keira Knightley and Brit...</td>\n",
       "      <td>BART</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A stunning new series of photographs of the la...</td>\n",
       "      <td>frida kahlo : the gisle freund photographs is...</td>\n",
       "      <td>BART</td>\n",
       "      <td>0</td>\n",
       "      <td>0.908302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On 11 January, 32-year-old Whittingham will ha...</td>\n",
       "      <td>Cardiff city manager neil warnock says he will...</td>\n",
       "      <td>BART</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>media playback is not supported on this device...</td>\n",
       "      <td>rugby union is back in england for the first t...</td>\n",
       "      <td>BART</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>Education Workforce Council figures showed 13 ...</td>\n",
       "      <td>More than a dozen teachers in Wales have been ...</td>\n",
       "      <td>BART</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>Aberdeenshire-based Harbro Group saw pre-tax p...</td>\n",
       "      <td>One of Scotland's largest suppliers of animal ...</td>\n",
       "      <td>Pegasus</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>The NHS Information Centre data shows more tha...</td>\n",
       "      <td>The number of babies being breastfed by their ...</td>\n",
       "      <td>BART</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>The Tiangong-1 or \"Heavenly Palace\" laboratory...</td>\n",
       "      <td>China's Tiangong-1 space station will burn up ...</td>\n",
       "      <td>BART</td>\n",
       "      <td>0</td>\n",
       "      <td>0.201280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2353 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               document  \\\n",
       "0     Media playback is not supported on this device...   \n",
       "1     There would have been no mercy in the dressing...   \n",
       "2     The couple, who have been dating since 2011, w...   \n",
       "3     A stunning new series of photographs of the la...   \n",
       "4     On 11 January, 32-year-old Whittingham will ha...   \n",
       "...                                                 ...   \n",
       "2348  media playback is not supported on this device...   \n",
       "2349  Education Workforce Council figures showed 13 ...   \n",
       "2350  Aberdeenshire-based Harbro Group saw pre-tax p...   \n",
       "2351  The NHS Information Centre data shows more tha...   \n",
       "2352  The Tiangong-1 or \"Heavenly Palace\" laboratory...   \n",
       "\n",
       "                                                summary    model  consistent  \\\n",
       "0     World number one Dustin Johnson has pulled out...     BART           0   \n",
       "1     ben stokes broke his wrist punching a locker a...       T5           1   \n",
       "2     Oscar-winning actress Keira Knightley and Brit...     BART           1   \n",
       "3     frida kahlo : the gisle freund photographs is...     BART           0   \n",
       "4     Cardiff city manager neil warnock says he will...     BART           0   \n",
       "...                                                 ...      ...         ...   \n",
       "2348  rugby union is back in england for the first t...     BART           0   \n",
       "2349  More than a dozen teachers in Wales have been ...     BART           1   \n",
       "2350  One of Scotland's largest suppliers of animal ...  Pegasus           1   \n",
       "2351  The number of babies being breastfed by their ...     BART           0   \n",
       "2352  China's Tiangong-1 space station will burn up ...     BART           0   \n",
       "\n",
       "      DAE_score  \n",
       "0      0.015970  \n",
       "1      0.874552  \n",
       "2      0.025989  \n",
       "3      0.908302  \n",
       "4      0.343225  \n",
       "...         ...  \n",
       "2348   0.012707  \n",
       "2349   0.145329  \n",
       "2350   0.754729  \n",
       "2351   0.016078  \n",
       "2352   0.201280  \n",
       "\n",
       "[2353 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da29b683-a97b-4dbd-8d54-7d2688529efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835229    0.000850\n",
      "0.864275    0.000850\n",
      "0.866869    0.000850\n",
      "0.909838    0.000850\n",
      "0.876568    0.000850\n",
      "              ...   \n",
      "0.843914    0.000425\n",
      "0.070338    0.000425\n",
      "0.151424    0.000425\n",
      "0.016949    0.000425\n",
      "0.201280    0.000425\n",
      "Name: labels, Length: 2348, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 2353\n",
      "total length 395460\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"AggreFact/data/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"regression\"\n",
    "dataset_name= \"aggrefact\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 34\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the following document and model summary, what DAE score would you assign to it?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Document: {row.document}. Summary: {row.summary}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.DAE_score]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa155595-e9e8-407a-8b49-e1ce42b3a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.671908\n",
      "0    0.328092\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 2353\n",
      "total length 397813\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"AggreFact/data/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"binary classification\"\n",
    "dataset_name= \"aggrefact\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 35\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Is the following model summary of the given article consistent or coherent?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Document: {row.document}. Summary: {row.summary}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.consistent]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731eaed-331c-4115-bdd5-3fb1d268fe7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08730c08-80e6-4b99-bc81-bea60b11244d",
   "metadata": {},
   "source": [
    "### PAR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d6d807b-427c-4b10-8fdc-7fa813abf182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"PAR3/annotUPWORK - all (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d67b52f6-9306-41f8-813a-a39743b8cc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['de', 'fr', 'ru'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lang_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81bb5c2f-741d-46d2-878c-fc1b595161e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text2    0.62\n",
      "text1    0.38\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 150\n",
      "total length 398113\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"PAR3/annotUPWORK - all (1).csv\")\n",
    "df = df[df.lang_code == \"ru\"]\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"binary classification\"\n",
    "dataset_name= \"par3_ru_en\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 37\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the source text, in Russian, and two translations, in English, which is a better translation?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} text1: {row.text1}. text2: {row.text2}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.gold]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "340f5aa3-194c-4eda-a192-c5f6057d4970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text2    0.58\n",
      "text1    0.42\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 150\n",
      "total length 398263\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"PAR3/annotUPWORK - all (1).csv\")\n",
    "df = df[df.lang_code == \"fr\"]\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"binary classification\"\n",
    "dataset_name= \"par3_fr_en\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 38\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Given the source text, in French, and two translations, in English, which is a better translation?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} text1: {row.text1}. text2: {row.text2}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.gold]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c39f6-f5a1-4630-b4e7-d69004765502",
   "metadata": {},
   "source": [
    "### Stories in the wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2850e029-cb07-404e-94f8-2e55fb318c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"stories_wild/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcb41ae7-69c9-4486-9c4d-1618c1610456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>coherent</th>\n",
       "      <th>confusing</th>\n",
       "      <th>creative</th>\n",
       "      <th>entertaining</th>\n",
       "      <th>grammatical</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. HABIA UNA VEZ UN PERRITO LLAMADO JERRY. POR...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog ran around the grassy forest. The dog ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dog named Harry Potter was at a park and he ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane ran. Jane ran. Jane ran. Jane ran. Jane r...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The police officer was getting into the argume...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>i can not get one. it is horibul. i like peein...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>A young man was casually walking down the stre...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>Mr. James ran up to Mr. Jonson because he want...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Once upon a time, a community tailor man took ...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>The man was tired, he sat down and though to h...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>702 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 story  coherent  confusing  \\\n",
       "0    1. HABIA UNA VEZ UN PERRITO LLAMADO JERRY. POR...         1          4   \n",
       "1    The dog ran around the grassy forest. The dog ...         6          1   \n",
       "2    A dog named Harry Potter was at a park and he ...         4          4   \n",
       "3    Jane ran. Jane ran. Jane ran. Jane ran. Jane r...         1          7   \n",
       "4    The police officer was getting into the argume...         5          2   \n",
       "..                                                 ...       ...        ...   \n",
       "697  i can not get one. it is horibul. i like peein...         1          6   \n",
       "698  A young man was casually walking down the stre...         7          4   \n",
       "699  Mr. James ran up to Mr. Jonson because he want...         2          6   \n",
       "700  Once upon a time, a community tailor man took ...         5          4   \n",
       "701  The man was tired, he sat down and though to h...         1          7   \n",
       "\n",
       "     creative  entertaining  grammatical  like  \n",
       "0           1             1            1     1  \n",
       "1           5             6            6     5  \n",
       "2           4             3            4     3  \n",
       "3           1             1            1     1  \n",
       "4           1             2            4     2  \n",
       "..        ...           ...          ...   ...  \n",
       "697         3             2            1     1  \n",
       "698         6             5            5     5  \n",
       "699         1             1            6     1  \n",
       "700         4             3            5     4  \n",
       "701         2             3            1     1  \n",
       "\n",
       "[702 rows x 7 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04d7d00d-a78e-4686-b0cb-c60d7fa779bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.232194\n",
      "6    0.202279\n",
      "4    0.170940\n",
      "3    0.163818\n",
      "2    0.103989\n",
      "7    0.064103\n",
      "1    0.062678\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 702\n",
      "total length 398965\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"stories_wild/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"stories_wild\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 39\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-7, how coherent or consistent would you rate the following story?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Story: {row.story}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.coherent]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02048834-d8d4-414c-949f-987e29462fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.203704\n",
      "3    0.180912\n",
      "2    0.178063\n",
      "4    0.158120\n",
      "5    0.139601\n",
      "6    0.092593\n",
      "7    0.047009\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 702\n",
      "total length 399667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"stories_wild/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"stories_wild\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 40\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-7, how confusing would you rate the following story?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Story: {row.story}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.confusing]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "add7014f-2d0d-4320-b6f9-7b4b90d4423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    0.272080\n",
      "5    0.216524\n",
      "3    0.189459\n",
      "2    0.129630\n",
      "6    0.089744\n",
      "1    0.078348\n",
      "7    0.024217\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 702\n",
      "total length 400369\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"stories_wild/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"stories_wild\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 41\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-7, how creative would you rate the following story?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Story: {row.story}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.creative]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6efff646-cf5a-4062-9a49-463c49a45191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.233618\n",
      "4    0.230769\n",
      "3    0.207977\n",
      "2    0.135328\n",
      "6    0.098291\n",
      "1    0.074074\n",
      "7    0.019943\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 702\n",
      "total length 401071\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"stories_wild/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"stories_wild\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 42\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-7, how fun, or entertaining, would you rate the following story?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Story: {row.story}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.entertaining]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16b9a7f6-79af-4db0-add4-0ee93ce89a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    0.196581\n",
      "6    0.192308\n",
      "4    0.179487\n",
      "3    0.138177\n",
      "2    0.121083\n",
      "1    0.108262\n",
      "7    0.064103\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 702\n",
      "total length 401773\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"stories_wild/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"stories_wild\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 43\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-7, how grammatically sound is the following story?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Story: {row.story}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.grammatical]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7facd95e-b887-4331-b9d0-720dad688366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f27794d6-f6e3-4cb5-8fe6-e7447715f500",
   "metadata": {},
   "source": [
    "### multipit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af4d3479-7ce6-49fd-bcaf-3a1a12e43159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"multi_pit/multipit_expert/train.csv\")\n",
    "df2 = pd.read_csv(\"multi_pit/multipit_expert/val.csv\")\n",
    "df3 = pd.read_csv(\"multi_pit/multipit_expert/test.csv\")\n",
    "\n",
    "df = pd.concat([df1,df2,df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9667107-bfbf-4c25-8ca6-c5ac488653ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today is the #wintersolstice , marking the beg...</td>\n",
       "      <td>It's the winter solstice in the northern hemis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today is the #wintersolstice , marking the beg...</td>\n",
       "      <td>Winter Solstice blessings + love to those in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Today is the #wintersolstice , marking the beg...</td>\n",
       "      <td>It's the first day of Northern Hemisphere wint...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today is the #wintersolstice , marking the beg...</td>\n",
       "      <td>Today is the first day of winter in Earth's No...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today is the #wintersolstice , marking the beg...</td>\n",
       "      <td>Happy Winter Solstice to all in the northern h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  Today is the #wintersolstice , marking the beg...   \n",
       "1  Today is the #wintersolstice , marking the beg...   \n",
       "2  Today is the #wintersolstice , marking the beg...   \n",
       "3  Today is the #wintersolstice , marking the beg...   \n",
       "4  Today is the #wintersolstice , marking the beg...   \n",
       "\n",
       "                                           sentence2  label  \n",
       "0  It's the winter solstice in the northern hemis...      1  \n",
       "1  Winter Solstice blessings + love to those in t...      0  \n",
       "2  It's the first day of Northern Hemisphere wint...      0  \n",
       "3  Today is the first day of winter in Earth's No...      1  \n",
       "4  Happy Winter Solstice to all in the northern h...      0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcf4f71f-7f6b-4ce3-84a2-711ac1512ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE     0.529982\n",
      "FALSE    0.470018\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 5570\n",
      "total length 407343\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"binary classification\"\n",
    "dataset_name= \"multipit\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 44\n",
    "SWITCH = {1: \"TRUE\", 0: \"FALSE\"}\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"Is sentence2 a paraphrase of sentence1?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Sentence1: {row.sentence1} Sentence2: {row.sentence2}</s>\"]\n",
    "    prelim_df[\"labels\"] += [SWITCH[row.label]]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ca0ce-6254-4240-ad1a-737415c2797a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07c5a0d3-571b-4ba3-9097-d85d61a69cc9",
   "metadata": {},
   "source": [
    "### MOCHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e05b37d-b0e1-40ee-96b3-df512ed9f35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.481270\n",
      "5    0.175523\n",
      "4    0.124123\n",
      "3    0.117510\n",
      "2    0.101574\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 35078\n",
      "total length 442421\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"MOCHA/data.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"mocha\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 45\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-5, how closely does the predicted answer match the correct answer given the context and the question?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Context: {row.context} Question: {row.question}. Predicted: {row.candidate}. Reference: {row.reference}</s>\"]\n",
    "    prelim_df[\"labels\"] += [row.score]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd1796a6-9057-412e-8d08-13524de2424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"MOCHA/data_pairs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48c557d7-499b-4073-ab76-77422a04f612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate1</th>\n",
       "      <th>candidate2</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>reference</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>better_candidate</th>\n",
       "      <th>better_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They want to repurpose that room</td>\n",
       "      <td>They want to give purpose that room</td>\n",
       "      <td>This wireless adapter is placed on the back of...</td>\n",
       "      <td>What's a possible reason the writer had to tak...</td>\n",
       "      <td>Because they needed the room for something else .</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>candidate1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>embibing alchool</td>\n",
       "      <td>drug use</td>\n",
       "      <td>We then drove to a friends house and seemingly...</td>\n",
       "      <td>What may have caused you to wake up in the mid...</td>\n",
       "      <td>I drank too much .</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>candidate1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To finish homework</td>\n",
       "      <td>To finish college</td>\n",
       "      <td>Well it's been a really wierd day . Mum , dad ...</td>\n",
       "      <td>What may have been your reason for staying in ...</td>\n",
       "      <td>I had to finish some assignments .</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>candidate1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ask my parents if I can go</td>\n",
       "      <td>my ask parents if I can go</td>\n",
       "      <td>[ 12 ] Where was your FIRST sleep over?No idea...</td>\n",
       "      <td>What did I do before going to Amy's house ?</td>\n",
       "      <td>I got my parents'permission .</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>candidate1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My phone calls are too long</td>\n",
       "      <td>My text messages are too long</td>\n",
       "      <td>Yesterday I worked and it was ok . Got in \" tr...</td>\n",
       "      <td>What may have caused you to get in trouble at ...</td>\n",
       "      <td>I couldn't end my talks with others .</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>candidate1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         candidate1                           candidate2  \\\n",
       "0  They want to repurpose that room  They want to give purpose that room   \n",
       "1                  embibing alchool                             drug use   \n",
       "2                To finish homework                    To finish college   \n",
       "3        ask my parents if I can go           my ask parents if I can go   \n",
       "4       My phone calls are too long        My text messages are too long   \n",
       "\n",
       "                                             context  \\\n",
       "0  This wireless adapter is placed on the back of...   \n",
       "1  We then drove to a friends house and seemingly...   \n",
       "2  Well it's been a really wierd day . Mum , dad ...   \n",
       "3  [ 12 ] Where was your FIRST sleep over?No idea...   \n",
       "4  Yesterday I worked and it was ok . Got in \" tr...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What's a possible reason the writer had to tak...   \n",
       "1  What may have caused you to wake up in the mid...   \n",
       "2  What may have been your reason for staying in ...   \n",
       "3        What did I do before going to Amy's house ?   \n",
       "4  What may have caused you to get in trouble at ...   \n",
       "\n",
       "                                           reference  score1  score2  \\\n",
       "0  Because they needed the room for something else .       5       2   \n",
       "1                                 I drank too much .       5       1   \n",
       "2                 I had to finish some assignments .       5       1   \n",
       "3                      I got my parents'permission .       5       3   \n",
       "4              I couldn't end my talks with others .       4       1   \n",
       "\n",
       "  better_candidate  better_score  \n",
       "0       candidate1             5  \n",
       "1       candidate1             5  \n",
       "2       candidate1             5  \n",
       "3       candidate1             5  \n",
       "4       candidate1             4  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac89228b-62db-43bd-af61-672d2790869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 1]    0.410\n",
      "[5, 2]    0.190\n",
      "[4, 1]    0.140\n",
      "[5, 3]    0.135\n",
      "[4, 2]    0.065\n",
      "[3, 1]    0.030\n",
      "[5, 4]    0.015\n",
      "[4, 3]    0.015\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 200\n",
      "total length 442621\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"MOCHA/data_pairs.csv\")\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multilabel multiclass classification\"\n",
    "dataset_name= \"mocha\"\n",
    "dataset_type= \"TRG\"\n",
    "task_id = 46\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-5, for how closely does each candidate match the reference answer?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    prelim_df[\"input_text\"] += [f\"{text_prompt} Context: {row.context} Question: {row.question}. Candidate1: {row.candidate1}. Candidate2: {row.candidate2}</s>\"]\n",
    "    prelim_df[\"labels\"] += [f\"[{row.score1}, {row.score2}]\"]\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f727ab6-d2a5-4201-a966-b6d6d96647ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c330ca4-59d1-4d77-8d0b-617301ec132d",
   "metadata": {},
   "source": [
    "### OAI SUMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0b76711-3215-48a0-bfc4-8189ea4f058b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>overall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>coverage</th>\n",
       "      <th>coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newcastle United midfielder Moussa Sissoko fac...</td>\n",
       "      <td>Newcastle stand-in skipper Moussa Sissoko is f...</td>\n",
       "      <td>Moussa Sissoko was sent off against Liverpool ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newcastle United midfielder Moussa Sissoko fac...</td>\n",
       "      <td>Newcastle stand-in skipper Moussa Sissoko is f...</td>\n",
       "      <td>Newcastle have a mountain to climb in the Prem...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Newcastle United midfielder Moussa Sissoko fac...</td>\n",
       "      <td>Newcastle stand-in skipper Moussa Sissoko is f...</td>\n",
       "      <td>Moussa Sissoko has been sent off following a d...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Newcastle United midfielder Moussa Sissoko fac...</td>\n",
       "      <td>Newcastle stand-in skipper Moussa Sissoko is f...</td>\n",
       "      <td>Moussa Sissoko is facing a disciplinary action...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newcastle United midfielder Moussa Sissoko fac...</td>\n",
       "      <td>Newcastle stand-in skipper Moussa Sissoko is f...</td>\n",
       "      <td>Newcastle need to start helping themselves now...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14883</th>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [18...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I want to ask out a girl on a date, general t...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14884</th>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [18...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Girl ignored me again, I cease conversation. ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14885</th>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [18...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [1...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14886</th>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [18...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Original](\\n(Clarification on this one, I di...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14887</th>\n",
       "      <td>[Update 2] I [18 M] want to ask out a girl [18...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I want to ask out a girl on a date, general t...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14888 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      Newcastle United midfielder Moussa Sissoko fac...   \n",
       "1      Newcastle United midfielder Moussa Sissoko fac...   \n",
       "2      Newcastle United midfielder Moussa Sissoko fac...   \n",
       "3      Newcastle United midfielder Moussa Sissoko fac...   \n",
       "4      Newcastle United midfielder Moussa Sissoko fac...   \n",
       "...                                                  ...   \n",
       "14883  [Update 2] I [18 M] want to ask out a girl [18...   \n",
       "14884  [Update 2] I [18 M] want to ask out a girl [18...   \n",
       "14885  [Update 2] I [18 M] want to ask out a girl [18...   \n",
       "14886  [Update 2] I [18 M] want to ask out a girl [18...   \n",
       "14887  [Update 2] I [18 M] want to ask out a girl [18...   \n",
       "\n",
       "                                                 article  \\\n",
       "0      Newcastle stand-in skipper Moussa Sissoko is f...   \n",
       "1      Newcastle stand-in skipper Moussa Sissoko is f...   \n",
       "2      Newcastle stand-in skipper Moussa Sissoko is f...   \n",
       "3      Newcastle stand-in skipper Moussa Sissoko is f...   \n",
       "4      Newcastle stand-in skipper Moussa Sissoko is f...   \n",
       "...                                                  ...   \n",
       "14883                                                NaN   \n",
       "14884                                                NaN   \n",
       "14885                                                NaN   \n",
       "14886                                                NaN   \n",
       "14887                                                NaN   \n",
       "\n",
       "                                                 summary  overall  accuracy  \\\n",
       "0      Moussa Sissoko was sent off against Liverpool ...      3.0       5.0   \n",
       "1      Newcastle have a mountain to climb in the Prem...      1.0       3.0   \n",
       "2      Moussa Sissoko has been sent off following a d...      2.0       4.0   \n",
       "3      Moussa Sissoko is facing a disciplinary action...      3.0       7.0   \n",
       "4      Newcastle need to start helping themselves now...      1.0       7.0   \n",
       "...                                                  ...      ...       ...   \n",
       "14883   I want to ask out a girl on a date, general t...      6.0       5.0   \n",
       "14884   Girl ignored me again, I cease conversation. ...      1.0       1.0   \n",
       "14885   [Update 2] I [18 M] want to ask out a girl [1...      7.0       7.0   \n",
       "14886   [Original](\\n(Clarification on this one, I di...      1.0       7.0   \n",
       "14887   I want to ask out a girl on a date, general t...      7.0       5.0   \n",
       "\n",
       "       coverage  coherence  \n",
       "0           4.0        2.0  \n",
       "1           1.0        1.0  \n",
       "2           2.0        2.0  \n",
       "3           3.0        6.0  \n",
       "4           1.0        3.0  \n",
       "...         ...        ...  \n",
       "14883       7.0        7.0  \n",
       "14884       1.0        7.0  \n",
       "14885       7.0        7.0  \n",
       "14886       1.0        7.0  \n",
       "14887       7.0        7.0  \n",
       "\n",
       "[14888 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54b79a1a-8591-47a6-880e-a7e31bd26ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60da6328-0211-4d96-bec1-c1301497a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    0.211890\n",
      "4    0.194779\n",
      "6    0.188489\n",
      "5    0.177465\n",
      "3    0.117003\n",
      "2    0.071216\n",
      "1    0.039159\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 14786\n",
      "total length 457407\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"OAI_summ/oai_summ/data.csv\")\n",
    "df = df[(df.overall.notna()) & (df.accuracy.notna()) & (df.coverage.notna()) & (df.coherence.notna())]\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"oai_summ\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 47\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-7, how would you rate the overall summary given the following article?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    if not isinstance(row.article, str) and math.isnan(row.article) and not math.isnan(row.overall):\n",
    "        prelim_df[\"input_text\"] += [f\"{text_prompt} Title: {row.title}. Summary: {row.summary}</s>\"]\n",
    "    else:\n",
    "        prelim_df[\"input_text\"] += [f\"{text_prompt} Title: {row.title}. Article: {row.article}. Summary: {row.summary}</s>\"]\n",
    "    prelim_df[\"labels\"] += [int(row.overall)]\n",
    "\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c2364e7-3619-4cda-a48a-907ad913f7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    0.684837\n",
      "5    0.115650\n",
      "6    0.068714\n",
      "4    0.063979\n",
      "3    0.030975\n",
      "2    0.020628\n",
      "1    0.015217\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 14786\n",
      "total length 472193\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"OAI_summ/oai_summ/data.csv\")\n",
    "df = df[(df.overall.notna()) & (df.accuracy.notna()) & (df.coverage.notna()) & (df.coherence.notna())]\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"oai_summ\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 48\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-7, how would you rate the accuracy of the summary given the following article?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    if not isinstance(row.article, str) and math.isnan(row.article):\n",
    "        prelim_df[\"input_text\"] += [f\"{text_prompt} Title: {row.title}. Summary: {row.summary}</s>\"]\n",
    "    else:\n",
    "        prelim_df[\"input_text\"] += [f\"{text_prompt} Title: {row.title}. Article: {row.article}. Summary: {row.summary}</s>\"]\n",
    "    prelim_df[\"labels\"] += [int(row.accuracy)]\n",
    "\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7f1a3691-4ec5-44bf-9871-3f80a0b1b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    0.244759\n",
      "4    0.205532\n",
      "6    0.172055\n",
      "5    0.161369\n",
      "3    0.102529\n",
      "2    0.065400\n",
      "1    0.048357\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 14786\n",
      "total length 486979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"OAI_summ/oai_summ/data.csv\")\n",
    "df = df[(df.overall.notna()) & (df.accuracy.notna()) & (df.coverage.notna()) & (df.coherence.notna())]\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"oai_summ\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 49\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-7, how would you rate the coverage of the summary given the following article?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    if not isinstance(row.article, str) and math.isnan(row.article):\n",
    "        prelim_df[\"input_text\"] += [f\"{text_prompt} Title: {row.title}. Summary: {row.summary}</s>\"]\n",
    "    else:\n",
    "        prelim_df[\"input_text\"] += [f\"{text_prompt} Title: {row.title}. Article: {row.article}. Summary: {row.summary}</s>\"]\n",
    "    prelim_df[\"labels\"] += [int(row.coverage)]\n",
    "\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0c8ea7e0-e5ea-412e-98c9-f97745f937fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    0.744556\n",
      "6    0.093129\n",
      "5    0.079670\n",
      "4    0.047545\n",
      "3    0.019884\n",
      "2    0.008589\n",
      "1    0.006628\n",
      "Name: labels, dtype: float64\n",
      "\n",
      "\n",
      "LENGTH: 14786\n",
      "total length 501765\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def merge_dfs(df1, df2):\n",
    "    merged_df = pd.concat([df1, df2]).sample(frac=1)\n",
    "    return merged_df\n",
    "\n",
    "df = pd.read_csv(\"OAI_summ/oai_summ/data.csv\")\n",
    "df = df[(df.overall.notna()) & (df.accuracy.notna()) & (df.coverage.notna()) & (df.coherence.notna())]\n",
    "master_df = pd.read_csv(\"master_dataset.csv\")\n",
    "\n",
    "prefix = \"multiclass classification\"\n",
    "dataset_name= \"oai_summ\"\n",
    "dataset_type= \"SRC\"\n",
    "task_id = 50\n",
    "prelim_df = {\"input_text\": [], \"labels\": [], \"prefix\": prefix, \"dataset\": dataset_name, \"dataset_type\": dataset_type, \"task_id\": task_id}\n",
    "\n",
    "text_prompt = \"On a scale from 1-7, how would you rate the coherence, or consistency, of the summary given the following article?\"\n",
    "\n",
    "for idx,row in df.iterrows():\n",
    "    \n",
    "    if not isinstance(row.article, str) and math.isnan(row.article):\n",
    "        prelim_df[\"input_text\"] += [f\"{text_prompt} Title: {row.title}. Summary: {row.summary}</s>\"]\n",
    "    else:\n",
    "        prelim_df[\"input_text\"] += [f\"{text_prompt} Title: {row.title}. Article: {row.article}. Summary: {row.summary}</s>\"]\n",
    "    prelim_df[\"labels\"] += [int(row.coherence)]\n",
    "\n",
    "    \n",
    "result_df = pd.DataFrame(prelim_df)\n",
    "\n",
    "print(result_df.labels.value_counts(normalize=True))\n",
    "print()\n",
    "print()\n",
    "print(f\"LENGTH: {len(result_df)}\")\n",
    "\n",
    "final_merged_df = merge_dfs(result_df, master_df)\n",
    "final_merged_df.to_csv(\"master_dataset.csv\", index=False)\n",
    "print(f\"total length {len(final_merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e2e228f0-5981-4ba9-81a3-d4aa0a26de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv(\"master_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "882ce5a5-d571-4918-ad7d-828503548f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501765"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44ff13-eb43-4008-96a9-5b441e1a7bff",
   "metadata": {},
   "source": [
    "### Storyium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "264329e7-ec0c-42b2-97cb-2ef0bed23261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "file_path = \"Storyium/storium_judgements.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3e15c3be-e72d-48cb-83f3-7be53a18cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "df = pd.read_json(path_or_buf=file_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fdb51211-622e-4400-b063-07f4774a8939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>generated</th>\n",
       "      <th>edited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt3-curie</td>\n",
       "      <td>\\nFresh air was what she was craving! Celosia'...</td>\n",
       "      <td>Celosia nodded, heading over. \\n\"I have my jac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt3-curie</td>\n",
       "      <td>\"You forgave me,\" Dinah said.  That was the p...</td>\n",
       "      <td>The battered ship slowly approached the Seasto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt3-curie</td>\n",
       "      <td>First thing's first, miss Rosenthal.  You've...</td>\n",
       "      <td>While getting away from the middle of nowhere ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt3-curie</td>\n",
       "      <td>\\nK9 and Jeb were sitting in the hotel bar doi...</td>\n",
       "      <td>K9 had rung the changes.\\n\\nWhilst Mr Wolf had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt3-curie</td>\n",
       "      <td>\"I know the feeling, Jenna.  Not having a clu...</td>\n",
       "      <td>Jenna looked nervous to Nick.\\n\\n\"I know the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>gpt3-davinci</td>\n",
       "      <td>\\nIt's  been a long day, and just when I think...</td>\n",
       "      <td>Fee seeing the young girl in pain walks over t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>gpt3-davinci</td>\n",
       "      <td>Fud had to admit Jasper had been right.  If t...</td>\n",
       "      <td>If they had not acted so suddenly and decisive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>gpt3-davinci</td>\n",
       "      <td>Douglas nervously said to no one in particula...</td>\n",
       "      <td>Douglas tried to stop him and shouted \"Stop ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>gpt3-davinci</td>\n",
       "      <td>\\n\\n\"Will someone please pay attention!\" yelle...</td>\n",
       "      <td>Quinn was with a group of students that were p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>gpt3-davinci</td>\n",
       "      <td>\\n\\nKotkell was still clutching the ****** pot...</td>\n",
       "      <td>Kotkell was still clutching the strange pot he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            model                                          generated  \\\n",
       "0      gpt3-curie  \\nFresh air was what she was craving! Celosia'...   \n",
       "1      gpt3-curie   \"You forgave me,\" Dinah said.  That was the p...   \n",
       "2      gpt3-curie    First thing's first, miss Rosenthal.  You've...   \n",
       "3      gpt3-curie  \\nK9 and Jeb were sitting in the hotel bar doi...   \n",
       "4      gpt3-curie   \"I know the feeling, Jenna.  Not having a clu...   \n",
       "..            ...                                                ...   \n",
       "551  gpt3-davinci  \\nIt's  been a long day, and just when I think...   \n",
       "552  gpt3-davinci   Fud had to admit Jasper had been right.  If t...   \n",
       "553  gpt3-davinci   Douglas nervously said to no one in particula...   \n",
       "554  gpt3-davinci  \\n\\n\"Will someone please pay attention!\" yelle...   \n",
       "555  gpt3-davinci  \\n\\nKotkell was still clutching the ****** pot...   \n",
       "\n",
       "                                                edited  \n",
       "0    Celosia nodded, heading over. \\n\"I have my jac...  \n",
       "1    The battered ship slowly approached the Seasto...  \n",
       "2    While getting away from the middle of nowhere ...  \n",
       "3    K9 had rung the changes.\\n\\nWhilst Mr Wolf had...  \n",
       "4    Jenna looked nervous to Nick.\\n\\n\"I know the f...  \n",
       "..                                                 ...  \n",
       "551  Fee seeing the young girl in pain walks over t...  \n",
       "552  If they had not acted so suddenly and decisive...  \n",
       "553  Douglas tried to stop him and shouted \"Stop ri...  \n",
       "554  Quinn was with a group of students that were p...  \n",
       "555  Kotkell was still clutching the strange pot he...  \n",
       "\n",
       "[556 rows x 3 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a820c8-c7d3-4288-8967-1ddbd6c4ea0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_try",
   "language": "python",
   "name": "final_try"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
