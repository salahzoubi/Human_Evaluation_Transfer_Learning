{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf03a30b-2dc7-4f97-90c4-6aca184beb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/salzubi_umass_edu/.conda/envs/wmt_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-09 10:47:33.853354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-09 10:47:34.100746: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-09 10:47:36.941561: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /modules/apps/julia/1.7.2/lib:/modules/apps/cuda/11.3.1/lib64\n",
      "2023-02-09 10:47:36.941787: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /modules/apps/julia/1.7.2/lib:/modules/apps/cuda/11.3.1/lib64\n",
      "2023-02-09 10:47:36.941806: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from data_utils import *\n",
    "from dataset import TLDataset\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer, AutoConfig\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from finetuner import T5FineTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b1877e-87a7-4854-894b-7e0b51908086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/salzubi_umass_edu/.conda/envs/wmt_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from multiprocessing import cpu_count\n",
    "import argparse\n",
    "output_path_dir = \"/home/salzubi_umass_edu/CKPTS/OAI_TRG_MODEL_CKPT/\"\n",
    "train_bsz = 4\n",
    "lr = 1e-3\n",
    "train_fraction = 1\n",
    "model_name = \"t5-small\"\n",
    "file_name = f\"OAI_trg_MODEL_task_Adam_lr:{lr}_bsz:{train_bsz}_frac:{train_fraction}_{model_name}\"\n",
    "num_gpus = torch.cuda.device_count()\n",
    "num_cpus = cpu_count()\n",
    "\n",
    "args_dict = dict(\n",
    "    # file_name = file_name,\n",
    "    # output_dir=output_path_dir, # path to save the checkpoints\n",
    "    model_name_or_path=model_name,\n",
    "    tokenizer_name_or_path=model_name,\n",
    "    max_seq_length=512,\n",
    "    train_fraction= train_fraction,\n",
    "    learning_rate=lr,\n",
    "    weight_decay=0.0,\n",
    "    scheduler_factor = .1,\n",
    "    use_gpu = True if num_gpus > 0 else False,\n",
    "    train_batch_size=train_bsz,\n",
    "    eval_batch_size=16,\n",
    "    num_train_steps=10000000,\n",
    "    es_patience = 4,\n",
    "    val_check_interval = .25,\n",
    "    dropout = .2,\n",
    "    n_gpu=num_gpus,\n",
    "    cpu_per_device=1,\n",
    "    task = \"classification\",\n",
    ")\n",
    "args = argparse.Namespace(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa8cd6e6-b27f-4366-ba71-2e0a5026771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = generate_transfer_splits(\"gofigure\", data_path = \"/work/salzubi_umass_edu/human_eval_datasets/master_dataset.csv\", random_state=1, train_fraction = args.train_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c99651c-4d95-4a6b-aadd-f1ea211a2008",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = T5FineTuner(hparams = args).load_from_checkpoint(\"../experiments/OAI_t5_large_train_fraction=1_TL.ckpt\", hparams = args)\n",
    "print(f\"loaded best model...\")\n",
    "test_loader = DataLoader(test_data, batch_size=int(args.eval_bsz), num_workers = num_cpus) #, num_workers=num_cpus//num_gpus\n",
    "\n",
    "y_preds = []\n",
    "y_true= []\n",
    "\n",
    "for idx, batch in enumerate(test_loader):\n",
    "\n",
    "    y_pred, y = process_test_output(batch, test_model, tokenizer)\n",
    "\n",
    "    y_preds += y_pred\n",
    "    y_true += y\n",
    "\n",
    "final_df = pd.DataFrame({\"predicted\": y_preds, \"ground_truth\": y_true})\n",
    "final_df.to_csv(f\"{args.output_dir}{args.file_name}_eval.csv\", index=False)\n",
    "print(\"finished!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529dd136-e5c7-4857-bb85-52e6f32272e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/salzubi_umass_edu/.conda/envs/wmt_env/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "random_seed = 1\n",
    "num_gpus = torch.cuda.device_count()\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5FineTuner(args)\n",
    "train, val, test = generate_transfer_splits(\"OAI\", data_path = \"/work/salzubi_umass_edu/human_eval_datasets/master_dataset.csv\", random_state=random_seed)\n",
    "train_data = TLDataset(train, tokenizer)\n",
    "val_data = TLDataset(val, tokenizer)\n",
    "test_data = TLDataset(test, tokenizer)\n",
    "train_sampler = generate_weighted_sampler(train)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=int(4), drop_last=True, shuffle=False) #sampler = sampler , num_workers=num_cpus//num_gpus\n",
    "val_loader = DataLoader(val_data, batch_size=int(16)) #, num_workers=num_cpus//num_gpus\n",
    "test_loader = DataLoader(test_data, batch_size=int(16)) #, num_workers=num_cpus//num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce74243-1634-4733-8afe-a249cd177a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "y_true=\n",
    "for idx, batch in tqdm(enumerate(test_loader)):\n",
    "    y_preds += generate_text_batch(batch, model, tokenizer)\n",
    "    y_true += tokenizer.batch_decode(batch['target_ids'], skip_special_tokens=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81874833-feab-4648-9bb2-ce9e82b8d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = batch[\"target_ids\"]\n",
    "labels[labels[:, :] == model.tokenizer.pad_token_id] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb58b4f-fde7-4077-8c52-8e9d51db97a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(\n",
    "  input_ids=batch[\"source_ids\"],\n",
    "  attention_mask=batch[\"source_mask\"],\n",
    "  labels=labels,\n",
    "  decoder_attention_mask=batch['target_mask']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7bc7c-a37f-4e64-a9b6-d0ff5db9a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import generate_text_from_example\n",
    "\n",
    "generated_text = generate_text_from_example(batch, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b5e3b-707f-4d42-831a-53143267dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ea6c4-5588-4963-b6ab-4eeed8f5f8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae12f361-4986-45c0-9c91-8f5f281b7da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77095\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../human_eval_datasets/master_dataset.csv\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65c66829-2293-4476-a868-086ab4b24ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0.602778\n",
       "B    0.397222\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.dataset == \"mauve\") & (df.dataset_type == \"SRC\")].labels.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749ea1f-aede-4199-8808-d6654cd49c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec42d7c-5d4c-4384-bc07-7278b39e6d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723bb0cf-c22c-4b44-9f40-a549388184dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd5de0c9-50cb-487c-b998-3072a4125d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = df[(df.dataset_type == \"TRG\") & (df.dataset == \"OAI\")]\n",
    "train_with = test_split.sample(int(.5 * len(test_split)))\n",
    "test_split = test_split[~test_split.index.isin(train_with.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d7e8a72-15fb-4a5a-b7cf-9bac1d002254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>prefix</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Answer the following question given the contex...</td>\n",
       "      <td>It stated, that Dark Castle was \"the best arca...</td>\n",
       "      <td>question answering</td>\n",
       "      <td>OAI</td>\n",
       "      <td>SRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Answer the following question given the contex...</td>\n",
       "      <td>Fox</td>\n",
       "      <td>question answering</td>\n",
       "      <td>OAI</td>\n",
       "      <td>SRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Answer the following question given the contex...</td>\n",
       "      <td>The team is comprised of doctors, nurses, phar...</td>\n",
       "      <td>question answering</td>\n",
       "      <td>OAI</td>\n",
       "      <td>SRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Answer the following question given the contex...</td>\n",
       "      <td>Fungi thrive in these areas.</td>\n",
       "      <td>question answering</td>\n",
       "      <td>OAI</td>\n",
       "      <td>SRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Answer the following question given the contex...</td>\n",
       "      <td>It might be implied it's not advisable because...</td>\n",
       "      <td>question answering</td>\n",
       "      <td>OAI</td>\n",
       "      <td>SRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77086</th>\n",
       "      <td>Answer the following question given the contex...</td>\n",
       "      <td>He might raise it as his own.</td>\n",
       "      <td>question answering</td>\n",
       "      <td>OAI</td>\n",
       "      <td>SRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77090</th>\n",
       "      <td>Answer the following question given the contex...</td>\n",
       "      <td>a historic home</td>\n",
       "      <td>question answering</td>\n",
       "      <td>OAI</td>\n",
       "      <td>SRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77091</th>\n",
       "      <td>Answer the following question given the contex...</td>\n",
       "      <td>After the ruling Puea Thai party tried to intr...</td>\n",
       "      <td>question answering</td>\n",
       "      <td>OAI</td>\n",
       "      <td>SRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77093</th>\n",
       "      <td>Which continuation is more likely to be writte...</td>\n",
       "      <td>B</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>mauve</td>\n",
       "      <td>SRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77094</th>\n",
       "      <td>Answer the following question given the contex...</td>\n",
       "      <td>February 7, 1984.</td>\n",
       "      <td>question answering</td>\n",
       "      <td>OAI</td>\n",
       "      <td>SRC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64636 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_text  \\\n",
       "0      Answer the following question given the contex...   \n",
       "1      Answer the following question given the contex...   \n",
       "2      Answer the following question given the contex...   \n",
       "3      Answer the following question given the contex...   \n",
       "5      Answer the following question given the contex...   \n",
       "...                                                  ...   \n",
       "77086  Answer the following question given the contex...   \n",
       "77090  Answer the following question given the contex...   \n",
       "77091  Answer the following question given the contex...   \n",
       "77093  Which continuation is more likely to be writte...   \n",
       "77094  Answer the following question given the contex...   \n",
       "\n",
       "                                                  labels  \\\n",
       "0      It stated, that Dark Castle was \"the best arca...   \n",
       "1                                                    Fox   \n",
       "2      The team is comprised of doctors, nurses, phar...   \n",
       "3                          Fungi thrive in these areas.    \n",
       "5      It might be implied it's not advisable because...   \n",
       "...                                                  ...   \n",
       "77086                      He might raise it as his own.   \n",
       "77090                                    a historic home   \n",
       "77091  After the ruling Puea Thai party tried to intr...   \n",
       "77093                                                  B   \n",
       "77094                                  February 7, 1984.   \n",
       "\n",
       "                      prefix dataset dataset_type  \n",
       "0         question answering     OAI          SRC  \n",
       "1         question answering     OAI          SRC  \n",
       "2         question answering     OAI          SRC  \n",
       "3         question answering     OAI          SRC  \n",
       "5         question answering     OAI          SRC  \n",
       "...                      ...     ...          ...  \n",
       "77086     question answering     OAI          SRC  \n",
       "77090     question answering     OAI          SRC  \n",
       "77091     question answering     OAI          SRC  \n",
       "77093  binary classification   mauve          SRC  \n",
       "77094     question answering     OAI          SRC  \n",
       "\n",
       "[64636 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.dataset_type == \"SRC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "575f489a-df29-4bfe-b653-28cfd4c29a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../human_eval_datasets/master_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aae6b8-5ef6-45bb-b8e6-86ea03813d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38f4f87-78b4-453a-8ee6-011ca2fb7437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>prefix</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>task_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Given the following question, which response i...</td>\n",
       "      <td>A</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>shp</td>\n",
       "      <td>SRC</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Given the following English to Chinese transla...</td>\n",
       "      <td>minor</td>\n",
       "      <td>multiclass classification</td>\n",
       "      <td>wmt_zh_en</td>\n",
       "      <td>SRC</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Given the following English to German translat...</td>\n",
       "      <td>no-error</td>\n",
       "      <td>multiclass classification</td>\n",
       "      <td>wmt_en_de</td>\n",
       "      <td>SRC</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given the following question, which response i...</td>\n",
       "      <td>A</td>\n",
       "      <td>binary classification</td>\n",
       "      <td>shp</td>\n",
       "      <td>SRC</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On a scale from 0-5, how similar are the two s...</td>\n",
       "      <td>0.800000011920929</td>\n",
       "      <td>regression</td>\n",
       "      <td>sts_b</td>\n",
       "      <td>SRC</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text             labels  \\\n",
       "0  Given the following question, which response i...                  A   \n",
       "1  Given the following English to Chinese transla...              minor   \n",
       "2  Given the following English to German translat...           no-error   \n",
       "3  Given the following question, which response i...                  A   \n",
       "4  On a scale from 0-5, how similar are the two s...  0.800000011920929   \n",
       "\n",
       "                      prefix    dataset dataset_type  task_id  \n",
       "0      binary classification        shp          SRC       64  \n",
       "1  multiclass classification  wmt_zh_en          SRC       16  \n",
       "2  multiclass classification  wmt_en_de          SRC       14  \n",
       "3      binary classification        shp          SRC       64  \n",
       "4                 regression      sts_b          SRC       55  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efdd0703-0efc-4287-a4c7-a611cde0bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = df[df.task_id==50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42bd670f-5a4c-49b3-905f-b8fcd8dac830",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset.to_csv(\"oai_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d74239-d45c-4a66-8b15-916b42c281cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-wmt_env)",
   "language": "python",
   "name": "conda-env-.conda-wmt_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
